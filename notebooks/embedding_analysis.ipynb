{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import iecdt_lab\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TILES_FILE = \"/gws/nopw/j04/iecdt/deep_learning_lab/1km_naturalcolor_numpy\"\n",
    "TEST_METADATA = \"/gws/nopw/j04/iecdt/deep_learning_lab/1km_naturalcolor_metadata_time_test.csv\"\n",
    "TILES_STATISTICS = \"/gws/nopw/j04/iecdt/deep_learning_lab/1km_naturalcolor_metadata_rgb_stats.npz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ResNet Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 1),\n",
    "    nn.Sigmoid(),  # Ensure that output lies between 0 and 1.\n",
    ")\n",
    "# If you want to load a model that you have trained use:\n",
    "# model.load_state_dict(torch.load(\"path/to/experiment/model.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stats = np.load(TILES_STATISTICS)\n",
    "data_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            mean=data_stats[\"rgb_mean\"], std=data_stats[\"rgb_std\"]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "test_ds = iecdt_lab.data_loader.GOESRGBTiles(\n",
    "    tiles_file=TILES_FILE,\n",
    "    metadata_file=TEST_METADATA,\n",
    "    transform=data_transforms,\n",
    ")\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the last layer of the ResNet so the model outputs the embeddings before the final layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "embedding_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the actual embeddings for all of the test dataset. This cell will take a couple of minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "for batch, labels in tqdm.tqdm(test_data_loader):\n",
    "    with torch.no_grad():\n",
    "        embeddings.append(embedding_model(batch).numpy())\n",
    "embeddings = np.concatenate(embeddings, axis=0)\n",
    "embeddings = embeddings.reshape(embeddings.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_tiles(cluster_labels, tile_dataset, num_samples=5) -> plt.Figure:\n",
    "    \"\"\"Plot the clusters of the test tiles. Each column is a cluster.\"\"\"\n",
    "    num_clusters = len(np.unique(cluster_labels))\n",
    "    fig, axs = plt.subplots(\n",
    "        num_samples, num_clusters, figsize=(num_clusters * 2, num_samples * 2)\n",
    "    )\n",
    "    for i in range(num_clusters):\n",
    "        cluster_ixs = np.where(cluster_labels == i)[0]\n",
    "        for j in range(num_samples):\n",
    "            if j < len(cluster_ixs):\n",
    "                tile, _ = tile_dataset[cluster_ixs[j]]\n",
    "                axs[j, i].imshow(tile)\n",
    "            axs[j, i].axis(\"off\")\n",
    "\n",
    "        axs[0, i].set_title(f\"Cluster {i}\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_clusters(cluster_labels, pca_embeddings) -> plt.Figure:\n",
    "    \"\"\"Plot the clusters in the PCA space.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    for i in np.unique(cluster_labels):\n",
    "        cluster_ixs = np.where(cluster_labels == i)[0]\n",
    "        ax.scatter(\n",
    "            pca_embeddings[cluster_ixs, 0],\n",
    "            pca_embeddings[cluster_ixs, 1],\n",
    "            label=f\"Cluster {i}\",\n",
    "        )\n",
    "    ax.legend()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get some understanding of how the embedding space is structured we will first reduce the embedding dimensionality using principal component analysis (PCA) and then cluster using KMeans. Feel free to experiment with different dimensionality reduction methods and clustering algorithms!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(pca_embeddings)\n",
    "cluster_labels = kmeans.predict(pca_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_clusters(cluster_labels, pca_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds_no_transform = iecdt_lab.data_loader.GOESRGBTiles(\n",
    "    tiles_file=TILES_FILE,\n",
    "    metadata_file=TEST_METADATA,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_cluster_tiles(cluster_labels, test_ds_no_transform, num_samples=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
